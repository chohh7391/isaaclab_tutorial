{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1209ee6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import torch\n",
    "from collections.abc import Sequence\n",
    "from typing import TYPE_CHECKING\n",
    "\n",
    "import omni.log\n",
    "from pxr import UsdPhysics\n",
    "\n",
    "import isaaclab.utils.math as math_utils\n",
    "import isaaclab.utils.string as string_utils\n",
    "from isaaclab.assets.articulation import Articulation\n",
    "from isaaclab.controllers.differential_ik import DifferentialIKController\n",
    "from isaaclab.controllers.operational_space import OperationalSpaceController\n",
    "from isaaclab.managers.action_manager import ActionTerm\n",
    "from isaaclab.sensors import ContactSensor, ContactSensorCfg, FrameTransformer, FrameTransformerCfg\n",
    "from isaaclab.sim.utils import find_matching_prims\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    from isaaclab.envs import ManagerBasedEnv\n",
    "    from isaaclab.envs.utils.io_descriptors import GenericActionIODescriptor\n",
    "\n",
    "    from . import actions_cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d5ec8e",
   "metadata": {},
   "source": [
    "# Differential IK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5254ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DifferentialInverseKinematicsAction(ActionTerm):\n",
    "    r\"\"\"Inverse Kinematics action term.\n",
    "\n",
    "    This action term performs pre-processing of the raw actions using scaling transformation.\n",
    "\n",
    "    .. math::\n",
    "        \\text{action} = \\text{scaling} \\times \\text{input action}\n",
    "        \\text{joint position} = J^{-} \\times \\text{action}\n",
    "\n",
    "    where :math:`\\text{scaling}` is the scaling applied to the input action, and :math:`\\text{input action}`\n",
    "    is the input action from the user, :math:`J` is the Jacobian over the articulation's actuated joints,\n",
    "    and \\text{joint position} is the desired joint position command for the articulation's joints.\n",
    "    \"\"\"\n",
    "\n",
    "    cfg: actions_cfg.DifferentialInverseKinematicsActionCfg\n",
    "    \"\"\"The configuration of the action term.\"\"\"\n",
    "    _asset: Articulation\n",
    "    \"\"\"The articulation asset on which the action term is applied.\"\"\"\n",
    "    _scale: torch.Tensor\n",
    "    \"\"\"The scaling factor applied to the input action. Shape is (1, action_dim).\"\"\"\n",
    "    _clip: torch.Tensor\n",
    "    \"\"\"The clip applied to the input action.\"\"\"\n",
    "\n",
    "    def __init__(self, cfg: actions_cfg.DifferentialInverseKinematicsActionCfg, env: ManagerBasedEnv):\n",
    "        # initialize the action term\n",
    "        super().__init__(cfg, env)\n",
    "\n",
    "        # resolve the joints over which the action term is applied\n",
    "        self._joint_ids, self._joint_names = self._asset.find_joints(self.cfg.joint_names)\n",
    "        self._num_joints = len(self._joint_ids)\n",
    "        # parse the body index\n",
    "        body_ids, body_names = self._asset.find_bodies(self.cfg.body_name)\n",
    "        if len(body_ids) != 1:\n",
    "            raise ValueError(\n",
    "                f\"Expected one match for the body name: {self.cfg.body_name}. Found {len(body_ids)}: {body_names}.\"\n",
    "            )\n",
    "        # save only the first body index\n",
    "        self._body_idx = body_ids[0]\n",
    "        self._body_name = body_names[0]\n",
    "        # check if articulation is fixed-base\n",
    "        # if fixed-base then the jacobian for the base is not computed\n",
    "        # this means that number of bodies is one less than the articulation's number of bodies\n",
    "        if self._asset.is_fixed_base:\n",
    "            self._jacobi_body_idx = self._body_idx - 1\n",
    "            self._jacobi_joint_ids = self._joint_ids\n",
    "        else:\n",
    "            self._jacobi_body_idx = self._body_idx\n",
    "            self._jacobi_joint_ids = [i + 6 for i in self._joint_ids]\n",
    "\n",
    "        # log info for debugging\n",
    "        omni.log.info(\n",
    "            f\"Resolved joint names for the action term {self.__class__.__name__}:\"\n",
    "            f\" {self._joint_names} [{self._joint_ids}]\"\n",
    "        )\n",
    "        omni.log.info(\n",
    "            f\"Resolved body name for the action term {self.__class__.__name__}: {self._body_name} [{self._body_idx}]\"\n",
    "        )\n",
    "        # Avoid indexing across all joints for efficiency\n",
    "        if self._num_joints == self._asset.num_joints:\n",
    "            self._joint_ids = slice(None)\n",
    "\n",
    "        # create the differential IK controller\n",
    "        self._ik_controller = DifferentialIKController(\n",
    "            cfg=self.cfg.controller, num_envs=self.num_envs, device=self.device\n",
    "        )\n",
    "\n",
    "        # create tensors for raw and processed actions\n",
    "        self._raw_actions = torch.zeros(self.num_envs, self.action_dim, device=self.device)\n",
    "        self._processed_actions = torch.zeros_like(self.raw_actions)\n",
    "\n",
    "        # save the scale as tensors\n",
    "        self._scale = torch.zeros((self.num_envs, self.action_dim), device=self.device)\n",
    "        self._scale[:] = torch.tensor(self.cfg.scale, device=self.device)\n",
    "\n",
    "        # convert the fixed offsets to torch tensors of batched shape\n",
    "        if self.cfg.body_offset is not None:\n",
    "            self._offset_pos = torch.tensor(self.cfg.body_offset.pos, device=self.device).repeat(self.num_envs, 1)\n",
    "            self._offset_rot = torch.tensor(self.cfg.body_offset.rot, device=self.device).repeat(self.num_envs, 1)\n",
    "        else:\n",
    "            self._offset_pos, self._offset_rot = None, None\n",
    "\n",
    "        # parse clip\n",
    "        if self.cfg.clip is not None:\n",
    "            if isinstance(cfg.clip, dict):\n",
    "                self._clip = torch.tensor([[-float(\"inf\"), float(\"inf\")]], device=self.device).repeat(\n",
    "                    self.num_envs, self.action_dim, 1\n",
    "                )\n",
    "                index_list, _, value_list = string_utils.resolve_matching_names_values(self.cfg.clip, self._joint_names)\n",
    "                self._clip[:, index_list] = torch.tensor(value_list, device=self.device)\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported clip type: {type(cfg.clip)}. Supported types are dict.\")\n",
    "\n",
    "    \"\"\"\n",
    "    Properties.\n",
    "    \"\"\"\n",
    "\n",
    "    @property\n",
    "    def action_dim(self) -> int:\n",
    "        return self._ik_controller.action_dim\n",
    "\n",
    "    @property\n",
    "    def raw_actions(self) -> torch.Tensor:\n",
    "        return self._raw_actions\n",
    "\n",
    "    @property\n",
    "    def processed_actions(self) -> torch.Tensor:\n",
    "        return self._processed_actions\n",
    "\n",
    "    @property\n",
    "    def jacobian_w(self) -> torch.Tensor:\n",
    "        return self._asset.root_physx_view.get_jacobians()[:, self._jacobi_body_idx, :, self._jacobi_joint_ids]\n",
    "\n",
    "    @property\n",
    "    def jacobian_b(self) -> torch.Tensor:\n",
    "        jacobian = self.jacobian_w\n",
    "        base_rot = self._asset.data.root_quat_w\n",
    "        base_rot_matrix = math_utils.matrix_from_quat(math_utils.quat_inv(base_rot))\n",
    "        jacobian[:, :3, :] = torch.bmm(base_rot_matrix, jacobian[:, :3, :])\n",
    "        jacobian[:, 3:, :] = torch.bmm(base_rot_matrix, jacobian[:, 3:, :])\n",
    "        return jacobian\n",
    "\n",
    "    @property\n",
    "    def IO_descriptor(self) -> GenericActionIODescriptor:\n",
    "        \"\"\"The IO descriptor of the action term.\n",
    "\n",
    "        This descriptor is used to describe the action term of the pink inverse kinematics action.\n",
    "        It adds the following information to the base descriptor:\n",
    "        - body_name: The name of the body.\n",
    "        - joint_names: The names of the joints.\n",
    "        - scale: The scale of the action term.\n",
    "        - clip: The clip of the action term.\n",
    "        - controller_cfg: The configuration of the controller.\n",
    "        - body_offset: The offset of the body.\n",
    "\n",
    "        Returns:\n",
    "            The IO descriptor of the action term.\n",
    "        \"\"\"\n",
    "        super().IO_descriptor\n",
    "        self._IO_descriptor.shape = (self.action_dim,)\n",
    "        self._IO_descriptor.dtype = str(self.raw_actions.dtype)\n",
    "        self._IO_descriptor.action_type = \"TaskSpaceAction\"\n",
    "        self._IO_descriptor.body_name = self._body_name\n",
    "        self._IO_descriptor.joint_names = self._joint_names\n",
    "        self._IO_descriptor.scale = self._scale\n",
    "        if self.cfg.clip is not None:\n",
    "            self._IO_descriptor.clip = self.cfg.clip\n",
    "        else:\n",
    "            self._IO_descriptor.clip = None\n",
    "        self._IO_descriptor.extras[\"controller_cfg\"] = self.cfg.controller.__dict__\n",
    "        self._IO_descriptor.extras[\"body_offset\"] = self.cfg.body_offset.__dict__\n",
    "        return self._IO_descriptor\n",
    "\n",
    "    \"\"\"\n",
    "    Operations.\n",
    "    \"\"\"\n",
    "\n",
    "    def process_actions(self, actions: torch.Tensor):\n",
    "        # store the raw actions\n",
    "        self._raw_actions[:] = actions\n",
    "        self._processed_actions[:] = self.raw_actions * self._scale\n",
    "        if self.cfg.clip is not None:\n",
    "            self._processed_actions = torch.clamp(\n",
    "                self._processed_actions, min=self._clip[:, :, 0], max=self._clip[:, :, 1]\n",
    "            )\n",
    "        # obtain quantities from simulation\n",
    "        ee_pos_curr, ee_quat_curr = self._compute_frame_pose()\n",
    "        # set command into controller\n",
    "        self._ik_controller.set_command(self._processed_actions, ee_pos_curr, ee_quat_curr)\n",
    "\n",
    "    def apply_actions(self):\n",
    "        # obtain quantities from simulation\n",
    "        ee_pos_curr, ee_quat_curr = self._compute_frame_pose()\n",
    "        joint_pos = self._asset.data.joint_pos[:, self._joint_ids]\n",
    "        # compute the delta in joint-space\n",
    "        if ee_quat_curr.norm() != 0:\n",
    "            jacobian = self._compute_frame_jacobian()\n",
    "            joint_pos_des = self._ik_controller.compute(ee_pos_curr, ee_quat_curr, jacobian, joint_pos)\n",
    "        else:\n",
    "            joint_pos_des = joint_pos.clone()\n",
    "        # set the joint position command\n",
    "        self._asset.set_joint_position_target(joint_pos_des, self._joint_ids)\n",
    "\n",
    "    def reset(self, env_ids: Sequence[int] | None = None) -> None:\n",
    "        self._raw_actions[env_ids] = 0.0\n",
    "\n",
    "    \"\"\"\n",
    "    Helper functions.\n",
    "    \"\"\"\n",
    "\n",
    "    def _compute_frame_pose(self) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Computes the pose of the target frame in the root frame.\n",
    "\n",
    "        Returns:\n",
    "            A tuple of the body's position and orientation in the root frame.\n",
    "        \"\"\"\n",
    "        # obtain quantities from simulation\n",
    "        ee_pos_w = self._asset.data.body_pos_w[:, self._body_idx]\n",
    "        ee_quat_w = self._asset.data.body_quat_w[:, self._body_idx]\n",
    "        root_pos_w = self._asset.data.root_pos_w\n",
    "        root_quat_w = self._asset.data.root_quat_w\n",
    "        # compute the pose of the body in the root frame\n",
    "        ee_pose_b, ee_quat_b = math_utils.subtract_frame_transforms(root_pos_w, root_quat_w, ee_pos_w, ee_quat_w)\n",
    "        # account for the offset\n",
    "        if self.cfg.body_offset is not None:\n",
    "            ee_pose_b, ee_quat_b = math_utils.combine_frame_transforms(\n",
    "                ee_pose_b, ee_quat_b, self._offset_pos, self._offset_rot\n",
    "            )\n",
    "\n",
    "        return ee_pose_b, ee_quat_b\n",
    "\n",
    "    def _compute_frame_jacobian(self):\n",
    "        \"\"\"Computes the geometric Jacobian of the target frame in the root frame.\n",
    "\n",
    "        This function accounts for the target frame offset and applies the necessary transformations to obtain\n",
    "        the right Jacobian from the parent body Jacobian.\n",
    "        \"\"\"\n",
    "        # read the parent jacobian\n",
    "        jacobian = self.jacobian_b\n",
    "        # account for the offset\n",
    "        if self.cfg.body_offset is not None:\n",
    "            # Modify the jacobian to account for the offset\n",
    "            # -- translational part\n",
    "            # v_link = v_ee + w_ee x r_link_ee = v_J_ee * q + w_J_ee * q x r_link_ee\n",
    "            #        = (v_J_ee + w_J_ee x r_link_ee ) * q\n",
    "            #        = (v_J_ee - r_link_ee_[x] @ w_J_ee) * q\n",
    "            jacobian[:, 0:3, :] += torch.bmm(-math_utils.skew_symmetric_matrix(self._offset_pos), jacobian[:, 3:, :])\n",
    "            # -- rotational part\n",
    "            # w_link = R_link_ee @ w_ee\n",
    "            jacobian[:, 3:, :] = torch.bmm(math_utils.matrix_from_quat(self._offset_rot), jacobian[:, 3:, :])\n",
    "\n",
    "        return jacobian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ba6452",
   "metadata": {},
   "source": [
    "# OSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750ebe11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OperationalSpaceControllerAction(ActionTerm):\n",
    "    r\"\"\"Operational space controller action term.\n",
    "\n",
    "    This action term performs pre-processing of the raw actions for operational space control.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    cfg: actions_cfg.OperationalSpaceControllerActionCfg\n",
    "    \"\"\"The configuration of the action term.\"\"\"\n",
    "    _asset: Articulation\n",
    "    \"\"\"The articulation asset on which the action term is applied.\"\"\"\n",
    "    _contact_sensor: ContactSensor = None\n",
    "    \"\"\"The contact sensor for the end-effector body.\"\"\"\n",
    "    _task_frame_transformer: FrameTransformer = None\n",
    "    \"\"\"The frame transformer for the task frame.\"\"\"\n",
    "\n",
    "    def __init__(self, cfg: actions_cfg.OperationalSpaceControllerActionCfg, env: ManagerBasedEnv):\n",
    "        # initialize the action term\n",
    "        super().__init__(cfg, env)\n",
    "\n",
    "        self._sim_dt = env.sim.get_physics_dt()\n",
    "\n",
    "        # resolve the joints over which the action term is applied\n",
    "        self._joint_ids, self._joint_names = self._asset.find_joints(self.cfg.joint_names)\n",
    "        self._num_DoF = len(self._joint_ids)\n",
    "        # parse the ee body index\n",
    "        body_ids, body_names = self._asset.find_bodies(self.cfg.body_name)\n",
    "        if len(body_ids) != 1:\n",
    "            raise ValueError(\n",
    "                f\"Expected one match for the ee body name: {self.cfg.body_name}. Found {len(body_ids)}: {body_names}.\"\n",
    "            )\n",
    "        # save only the first ee body index\n",
    "        self._ee_body_idx = body_ids[0]\n",
    "        self._ee_body_name = body_names[0]\n",
    "        # check if articulation is fixed-base\n",
    "        # if fixed-base then the jacobian for the base is not computed\n",
    "        # this means that number of bodies is one less than the articulation's number of bodies\n",
    "        if self._asset.is_fixed_base:\n",
    "            self._jacobi_ee_body_idx = self._ee_body_idx - 1\n",
    "            self._jacobi_joint_idx = self._joint_ids\n",
    "        else:\n",
    "            self._jacobi_ee_body_idx = self._ee_body_idx\n",
    "            self._jacobi_joint_idx = [i + 6 for i in self._joint_ids]\n",
    "\n",
    "        # log info for debugging\n",
    "        omni.log.info(\n",
    "            f\"Resolved joint names for the action term {self.__class__.__name__}:\"\n",
    "            f\" {self._joint_names} [{self._joint_ids}]\"\n",
    "        )\n",
    "        omni.log.info(\n",
    "            f\"Resolved ee body name for the action term {self.__class__.__name__}:\"\n",
    "            f\" {self._ee_body_name} [{self._ee_body_idx}]\"\n",
    "        )\n",
    "        # Avoid indexing across all joints for efficiency\n",
    "        if self._num_DoF == self._asset.num_joints:\n",
    "            self._joint_ids = slice(None)\n",
    "\n",
    "        # convert the fixed offsets to torch tensors of batched shape\n",
    "        if self.cfg.body_offset is not None:\n",
    "            self._offset_pos = torch.tensor(self.cfg.body_offset.pos, device=self.device).repeat(self.num_envs, 1)\n",
    "            self._offset_rot = torch.tensor(self.cfg.body_offset.rot, device=self.device).repeat(self.num_envs, 1)\n",
    "        else:\n",
    "            self._offset_pos, self._offset_rot = None, None\n",
    "\n",
    "        # create contact sensor if any of the command is wrench_abs, and if stiffness is provided\n",
    "        if (\n",
    "            \"wrench_abs\" in self.cfg.controller_cfg.target_types\n",
    "            and self.cfg.controller_cfg.contact_wrench_stiffness_task is not None\n",
    "        ):\n",
    "            self._contact_sensor_cfg = ContactSensorCfg(prim_path=self._asset.cfg.prim_path + \"/\" + self._ee_body_name)\n",
    "            self._contact_sensor = ContactSensor(self._contact_sensor_cfg)\n",
    "            if not self._contact_sensor.is_initialized:\n",
    "                self._contact_sensor._initialize_impl()\n",
    "                self._contact_sensor._is_initialized = True\n",
    "\n",
    "        # Initialize the task frame transformer if a relative path for the RigidObject, representing the task frame,\n",
    "        # is provided.\n",
    "        if self.cfg.task_frame_rel_path is not None:\n",
    "            # The source RigidObject can be any child of the articulation asset (we will not use it),\n",
    "            # hence, we will use the first RigidObject child.\n",
    "            root_rigidbody_path = self._first_RigidObject_child_path()\n",
    "            task_frame_transformer_path = \"/World/envs/env_.*/\" + self.cfg.task_frame_rel_path\n",
    "            task_frame_transformer_cfg = FrameTransformerCfg(\n",
    "                prim_path=root_rigidbody_path,\n",
    "                target_frames=[\n",
    "                    FrameTransformerCfg.FrameCfg(\n",
    "                        name=\"task_frame\",\n",
    "                        prim_path=task_frame_transformer_path,\n",
    "                    ),\n",
    "                ],\n",
    "            )\n",
    "            self._task_frame_transformer = FrameTransformer(task_frame_transformer_cfg)\n",
    "            if not self._task_frame_transformer.is_initialized:\n",
    "                self._task_frame_transformer._initialize_impl()\n",
    "                self._task_frame_transformer._is_initialized = True\n",
    "            # create tensor for task frame pose in the root frame\n",
    "            self._task_frame_pose_b = torch.zeros(self.num_envs, 7, device=self.device)\n",
    "        else:\n",
    "            # create an empty reference for task frame pose\n",
    "            self._task_frame_pose_b = None\n",
    "\n",
    "        # create the operational space controller\n",
    "        self._osc = OperationalSpaceController(cfg=self.cfg.controller_cfg, num_envs=self.num_envs, device=self.device)\n",
    "\n",
    "        # create tensors for raw and processed actions\n",
    "        self._raw_actions = torch.zeros(self.num_envs, self.action_dim, device=self.device)\n",
    "        self._processed_actions = torch.zeros_like(self.raw_actions)\n",
    "\n",
    "        # create tensors for the dynamic-related quantities\n",
    "        self._jacobian_b = torch.zeros(self.num_envs, 6, self._num_DoF, device=self.device)\n",
    "        self._mass_matrix = torch.zeros(self.num_envs, self._num_DoF, self._num_DoF, device=self.device)\n",
    "        self._gravity = torch.zeros(self.num_envs, self._num_DoF, device=self.device)\n",
    "\n",
    "        # create tensors for the ee states\n",
    "        self._ee_pose_w = torch.zeros(self.num_envs, 7, device=self.device)\n",
    "        self._ee_pose_b = torch.zeros(self.num_envs, 7, device=self.device)\n",
    "        self._ee_pose_b_no_offset = torch.zeros(self.num_envs, 7, device=self.device)  # The original ee without offset\n",
    "        self._ee_vel_w = torch.zeros(self.num_envs, 6, device=self.device)\n",
    "        self._ee_vel_b = torch.zeros(self.num_envs, 6, device=self.device)\n",
    "        self._ee_force_w = torch.zeros(self.num_envs, 3, device=self.device)  # Only the forces are used for now\n",
    "        self._ee_force_b = torch.zeros(self.num_envs, 3, device=self.device)  # Only the forces are used for now\n",
    "\n",
    "        # create tensors for the joint states\n",
    "        self._joint_pos = torch.zeros(self.num_envs, self._num_DoF, device=self.device)\n",
    "        self._joint_vel = torch.zeros(self.num_envs, self._num_DoF, device=self.device)\n",
    "\n",
    "        # create the joint effort tensor\n",
    "        self._joint_efforts = torch.zeros(self.num_envs, self._num_DoF, device=self.device)\n",
    "\n",
    "        # save the scale as tensors\n",
    "        self._position_scale = torch.tensor(self.cfg.position_scale, device=self.device)\n",
    "        self._orientation_scale = torch.tensor(self.cfg.orientation_scale, device=self.device)\n",
    "        self._wrench_scale = torch.tensor(self.cfg.wrench_scale, device=self.device)\n",
    "        self._stiffness_scale = torch.tensor(self.cfg.stiffness_scale, device=self.device)\n",
    "        self._damping_ratio_scale = torch.tensor(self.cfg.damping_ratio_scale, device=self.device)\n",
    "\n",
    "        # indexes for the various command elements (e.g., pose_rel, stifness, etc.) within the command tensor\n",
    "        self._pose_abs_idx = None\n",
    "        self._pose_rel_idx = None\n",
    "        self._wrench_abs_idx = None\n",
    "        self._stiffness_idx = None\n",
    "        self._damping_ratio_idx = None\n",
    "        self._resolve_command_indexes()\n",
    "\n",
    "        # Nullspace position control joint targets\n",
    "        self._nullspace_joint_pos_target = None\n",
    "        self._resolve_nullspace_joint_pos_targets()\n",
    "\n",
    "    \"\"\"\n",
    "    Properties.\n",
    "    \"\"\"\n",
    "\n",
    "    @property\n",
    "    def action_dim(self) -> int:\n",
    "        \"\"\"Dimension of the action space of operational space control.\"\"\"\n",
    "        return self._osc.action_dim\n",
    "\n",
    "    @property\n",
    "    def raw_actions(self) -> torch.Tensor:\n",
    "        \"\"\"Raw actions for operational space control.\"\"\"\n",
    "        return self._raw_actions\n",
    "\n",
    "    @property\n",
    "    def processed_actions(self) -> torch.Tensor:\n",
    "        \"\"\"Processed actions for operational space control.\"\"\"\n",
    "        return self._processed_actions\n",
    "\n",
    "    @property\n",
    "    def jacobian_w(self) -> torch.Tensor:\n",
    "        return self._asset.root_physx_view.get_jacobians()[:, self._jacobi_ee_body_idx, :, self._jacobi_joint_idx]\n",
    "\n",
    "    @property\n",
    "    def jacobian_b(self) -> torch.Tensor:\n",
    "        jacobian = self.jacobian_w\n",
    "        base_rot = self._asset.data.root_quat_w\n",
    "        base_rot_matrix = math_utils.matrix_from_quat(math_utils.quat_inv(base_rot))\n",
    "        jacobian[:, :3, :] = torch.bmm(base_rot_matrix, jacobian[:, :3, :])\n",
    "        jacobian[:, 3:, :] = torch.bmm(base_rot_matrix, jacobian[:, 3:, :])\n",
    "        return jacobian\n",
    "\n",
    "    @property\n",
    "    def IO_descriptor(self) -> GenericActionIODescriptor:\n",
    "        \"\"\"The IO descriptor of the action term.\n",
    "\n",
    "        This descriptor is used to describe the action term of the pink inverse kinematics action.\n",
    "        It adds the following information to the base descriptor:\n",
    "        - body_name: The name of the body.\n",
    "        - joint_names: The names of the joints.\n",
    "        - position_scale: The scale of the position.\n",
    "        - orientation_scale: The scale of the orientation.\n",
    "        - wrench_scale: The scale of the wrench.\n",
    "        - stiffness_scale: The scale of the stiffness.\n",
    "        - damping_ratio_scale: The scale of the damping ratio.\n",
    "        - nullspace_joint_pos_target: The nullspace joint pos target.\n",
    "        - clip: The clip of the action term.\n",
    "        - controller_cfg: The configuration of the controller.\n",
    "        - body_offset: The offset of the body.\n",
    "\n",
    "        Returns:\n",
    "            The IO descriptor of the action term.\n",
    "        \"\"\"\n",
    "        super().IO_descriptor\n",
    "        self._IO_descriptor.shape = (self.action_dim,)\n",
    "        self._IO_descriptor.dtype = str(self.raw_actions.dtype)\n",
    "        self._IO_descriptor.action_type = \"TaskSpaceAction\"\n",
    "        self._IO_descriptor.body_name = self._ee_body_name\n",
    "        self._IO_descriptor.joint_names = self._joint_names\n",
    "        self._IO_descriptor.position_scale = self.cfg.position_scale\n",
    "        self._IO_descriptor.orientation_scale = self.cfg.orientation_scale\n",
    "        self._IO_descriptor.wrench_scale = self.cfg.wrench_scale\n",
    "        self._IO_descriptor.stiffness_scale = self.cfg.stiffness_scale\n",
    "        self._IO_descriptor.damping_ratio_scale = self.cfg.damping_ratio_scale\n",
    "        self._IO_descriptor.nullspace_joint_pos_target = self.cfg.nullspace_joint_pos_target\n",
    "        if self.cfg.clip is not None:\n",
    "            self._IO_descriptor.clip = self.cfg.clip\n",
    "        else:\n",
    "            self._IO_descriptor.clip = None\n",
    "        self._IO_descriptor.extras[\"controller_cfg\"] = self.cfg.controller_cfg.__dict__\n",
    "        self._IO_descriptor.extras[\"body_offset\"] = self.cfg.body_offset.__dict__\n",
    "        return self._IO_descriptor\n",
    "\n",
    "    \"\"\"\n",
    "    Operations.\n",
    "    \"\"\"\n",
    "\n",
    "    def process_actions(self, actions: torch.Tensor):\n",
    "        \"\"\"Pre-processes the raw actions and sets them as commands for for operational space control.\n",
    "\n",
    "        Args:\n",
    "            actions (torch.Tensor): The raw actions for operational space control. It is a tensor of\n",
    "                shape (``num_envs``, ``action_dim``).\n",
    "        \"\"\"\n",
    "\n",
    "        # Update ee pose, which would be used by relative targets (i.e., pose_rel)\n",
    "        self._compute_ee_pose()\n",
    "\n",
    "        # Update task frame pose w.r.t. the root frame.\n",
    "        self._compute_task_frame_pose()\n",
    "\n",
    "        # Pre-process the raw actions for operational space control.\n",
    "        self._preprocess_actions(actions)\n",
    "\n",
    "        # set command into controller\n",
    "        self._osc.set_command(\n",
    "            command=self._processed_actions,\n",
    "            current_ee_pose_b=self._ee_pose_b,\n",
    "            current_task_frame_pose_b=self._task_frame_pose_b,\n",
    "        )\n",
    "\n",
    "    def apply_actions(self):\n",
    "        \"\"\"Computes the joint efforts for operational space control and applies them to the articulation.\"\"\"\n",
    "\n",
    "        # Update the relevant states and dynamical quantities\n",
    "        self._compute_dynamic_quantities()\n",
    "        self._compute_ee_jacobian()\n",
    "        self._compute_ee_pose()\n",
    "        self._compute_ee_velocity()\n",
    "        self._compute_ee_force()\n",
    "        self._compute_joint_states()\n",
    "        # Calculate the joint efforts\n",
    "        self._joint_efforts[:] = self._osc.compute(\n",
    "            jacobian_b=self._jacobian_b,\n",
    "            current_ee_pose_b=self._ee_pose_b,\n",
    "            current_ee_vel_b=self._ee_vel_b,\n",
    "            current_ee_force_b=self._ee_force_b,\n",
    "            mass_matrix=self._mass_matrix,\n",
    "            gravity=self._gravity,\n",
    "            current_joint_pos=self._joint_pos,\n",
    "            current_joint_vel=self._joint_vel,\n",
    "            nullspace_joint_pos_target=self._nullspace_joint_pos_target,\n",
    "        )\n",
    "        self._asset.set_joint_effort_target(self._joint_efforts, joint_ids=self._joint_ids)\n",
    "\n",
    "    def reset(self, env_ids: Sequence[int] | None = None) -> None:\n",
    "        \"\"\"Resets the raw actions and the sensors if available.\n",
    "\n",
    "        Args:\n",
    "            env_ids (Sequence[int] | None): The environment indices to reset. If ``None``, all environments are reset.\n",
    "        \"\"\"\n",
    "        self._raw_actions[env_ids] = 0.0\n",
    "        if self._contact_sensor is not None:\n",
    "            self._contact_sensor.reset(env_ids)\n",
    "        if self._task_frame_transformer is not None:\n",
    "            self._task_frame_transformer.reset(env_ids)\n",
    "\n",
    "    \"\"\"\n",
    "    Helper functions.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def _first_RigidObject_child_path(self):\n",
    "        \"\"\"Finds the first ``RigidObject`` child under the articulation asset.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If no child ``RigidObject`` is found under the articulation asset.\n",
    "\n",
    "        Returns:\n",
    "            str: The path to the first ``RigidObject`` child under the articulation asset.\n",
    "        \"\"\"\n",
    "        child_prims = find_matching_prims(self._asset.cfg.prim_path + \"/.*\")\n",
    "        rigid_child_prim = None\n",
    "        # Loop through the list and stop at the first RigidObject found\n",
    "        for prim in child_prims:\n",
    "            if prim.HasAPI(UsdPhysics.RigidBodyAPI):\n",
    "                rigid_child_prim = prim\n",
    "                break\n",
    "        if rigid_child_prim is None:\n",
    "            raise ValueError(\"No child rigid body found under the expression: '{self._asset.cfg.prim_path}'/.\")\n",
    "        rigid_child_prim_path = rigid_child_prim.GetPath().pathString\n",
    "        # Remove the specific env index from the path string\n",
    "        rigid_child_prim_path = self._asset.cfg.prim_path + \"/\" + rigid_child_prim_path.split(\"/\")[-1]\n",
    "        return rigid_child_prim_path\n",
    "\n",
    "    def _resolve_command_indexes(self):\n",
    "        \"\"\"Resolves the indexes for the various command elements within the command tensor.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If any command index is left unresolved.\n",
    "        \"\"\"\n",
    "        # First iterate over the target types to find the indexes of the different command elements\n",
    "        cmd_idx = 0\n",
    "        for target_type in self.cfg.controller_cfg.target_types:\n",
    "            if target_type == \"pose_abs\":\n",
    "                self._pose_abs_idx = cmd_idx\n",
    "                cmd_idx += 7\n",
    "            elif target_type == \"pose_rel\":\n",
    "                self._pose_rel_idx = cmd_idx\n",
    "                cmd_idx += 6\n",
    "            elif target_type == \"wrench_abs\":\n",
    "                self._wrench_abs_idx = cmd_idx\n",
    "                cmd_idx += 6\n",
    "            else:\n",
    "                raise ValueError(\"Undefined target_type for OSC within OperationalSpaceControllerAction.\")\n",
    "        # Then iterate over the impedance parameters depending on the impedance mode\n",
    "        if (\n",
    "            self.cfg.controller_cfg.impedance_mode == \"variable_kp\"\n",
    "            or self.cfg.controller_cfg.impedance_mode == \"variable\"\n",
    "        ):\n",
    "            self._stiffness_idx = cmd_idx\n",
    "            cmd_idx += 6\n",
    "            if self.cfg.controller_cfg.impedance_mode == \"variable\":\n",
    "                self._damping_ratio_idx = cmd_idx\n",
    "                cmd_idx += 6\n",
    "\n",
    "        # Check if any command is left unresolved\n",
    "        if self.action_dim != cmd_idx:\n",
    "            raise ValueError(\"Not all command indexes have been resolved.\")\n",
    "\n",
    "    def _resolve_nullspace_joint_pos_targets(self):\n",
    "        \"\"\"Resolves the nullspace joint pos targets for the operational space controller.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If the nullspace joint pos targets are set when null space control is not set to 'position'.\n",
    "            ValueError: If the nullspace joint pos targets are not set when null space control is set to 'position'.\n",
    "            ValueError: If an invalid value is set for nullspace joint pos targets.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.cfg.nullspace_joint_pos_target != \"none\" and self.cfg.controller_cfg.nullspace_control != \"position\":\n",
    "            raise ValueError(\"Nullspace joint targets can only be set when null space control is set to 'position'.\")\n",
    "\n",
    "        if self.cfg.nullspace_joint_pos_target == \"none\" and self.cfg.controller_cfg.nullspace_control == \"position\":\n",
    "            raise ValueError(\"Nullspace joint targets must be set when null space control is set to 'position'.\")\n",
    "\n",
    "        if self.cfg.nullspace_joint_pos_target == \"zero\" or self.cfg.nullspace_joint_pos_target == \"none\":\n",
    "            # Keep the nullspace joint targets as None as this is later processed as zero in the controller\n",
    "            self._nullspace_joint_pos_target = None\n",
    "        elif self.cfg.nullspace_joint_pos_target == \"center\":\n",
    "            # Get the center of the robot soft joint limits\n",
    "            self._nullspace_joint_pos_target = torch.mean(\n",
    "                self._asset.data.soft_joint_pos_limits[:, self._joint_ids, :], dim=-1\n",
    "            )\n",
    "        elif self.cfg.nullspace_joint_pos_target == \"default\":\n",
    "            # Get the default joint positions\n",
    "            self._nullspace_joint_pos_target = self._asset.data.default_joint_pos[:, self._joint_ids]\n",
    "        else:\n",
    "            raise ValueError(\"Invalid value for nullspace joint pos targets.\")\n",
    "\n",
    "    def _compute_dynamic_quantities(self):\n",
    "        \"\"\"Computes the dynamic quantities for operational space control.\"\"\"\n",
    "\n",
    "        self._mass_matrix[:] = self._asset.root_physx_view.get_generalized_mass_matrices()[:, self._joint_ids, :][\n",
    "            :, :, self._joint_ids\n",
    "        ]\n",
    "        self._gravity[:] = self._asset.root_physx_view.get_gravity_compensation_forces()[:, self._joint_ids]\n",
    "\n",
    "    def _compute_ee_jacobian(self):\n",
    "        \"\"\"Computes the geometric Jacobian of the ee body frame in root frame.\n",
    "\n",
    "        This function accounts for the target frame offset and applies the necessary transformations to obtain\n",
    "        the right Jacobian from the parent body Jacobian.\n",
    "        \"\"\"\n",
    "        # Get the Jacobian in root frame\n",
    "        self._jacobian_b[:] = self.jacobian_b\n",
    "\n",
    "        # account for the offset\n",
    "        if self.cfg.body_offset is not None:\n",
    "            # Modify the jacobian to account for the offset\n",
    "            # -- translational part\n",
    "            # v_link = v_ee + w_ee x r_link_ee = v_J_ee * q + w_J_ee * q x r_link_ee\n",
    "            #        = (v_J_ee + w_J_ee x r_link_ee ) * q\n",
    "            #        = (v_J_ee - r_link_ee_[x] @ w_J_ee) * q\n",
    "            self._jacobian_b[:, 0:3, :] += torch.bmm(-math_utils.skew_symmetric_matrix(self._offset_pos), self._jacobian_b[:, 3:, :])  # type: ignore\n",
    "            # -- rotational part\n",
    "            # w_link = R_link_ee @ w_ee\n",
    "            self._jacobian_b[:, 3:, :] = torch.bmm(math_utils.matrix_from_quat(self._offset_rot), self._jacobian_b[:, 3:, :])  # type: ignore\n",
    "\n",
    "    def _compute_ee_pose(self):\n",
    "        \"\"\"Computes the pose of the ee frame in root frame.\"\"\"\n",
    "        # Obtain quantities from simulation\n",
    "        self._ee_pose_w[:, 0:3] = self._asset.data.body_pos_w[:, self._ee_body_idx]\n",
    "        self._ee_pose_w[:, 3:7] = self._asset.data.body_quat_w[:, self._ee_body_idx]\n",
    "        # Compute the pose of the ee body in the root frame\n",
    "        self._ee_pose_b_no_offset[:, 0:3], self._ee_pose_b_no_offset[:, 3:7] = math_utils.subtract_frame_transforms(\n",
    "            self._asset.data.root_pos_w,\n",
    "            self._asset.data.root_quat_w,\n",
    "            self._ee_pose_w[:, 0:3],\n",
    "            self._ee_pose_w[:, 3:7],\n",
    "        )\n",
    "        # Account for the offset\n",
    "        if self.cfg.body_offset is not None:\n",
    "            self._ee_pose_b[:, 0:3], self._ee_pose_b[:, 3:7] = math_utils.combine_frame_transforms(\n",
    "                self._ee_pose_b_no_offset[:, 0:3], self._ee_pose_b_no_offset[:, 3:7], self._offset_pos, self._offset_rot\n",
    "            )\n",
    "        else:\n",
    "            self._ee_pose_b[:] = self._ee_pose_b_no_offset\n",
    "\n",
    "    def _compute_ee_velocity(self):\n",
    "        \"\"\"Computes the velocity of the ee frame in root frame.\"\"\"\n",
    "        # Extract end-effector velocity in the world frame\n",
    "        self._ee_vel_w[:] = self._asset.data.body_vel_w[:, self._ee_body_idx, :]\n",
    "        # Compute the relative velocity in the world frame\n",
    "        relative_vel_w = self._ee_vel_w - self._asset.data.root_vel_w\n",
    "\n",
    "        # Convert ee velocities from world to root frame\n",
    "        self._ee_vel_b[:, 0:3] = math_utils.quat_apply_inverse(self._asset.data.root_quat_w, relative_vel_w[:, 0:3])\n",
    "        self._ee_vel_b[:, 3:6] = math_utils.quat_apply_inverse(self._asset.data.root_quat_w, relative_vel_w[:, 3:6])\n",
    "\n",
    "        # Account for the offset\n",
    "        if self.cfg.body_offset is not None:\n",
    "            # Compute offset vector in root frame\n",
    "            r_offset_b = math_utils.quat_apply(self._ee_pose_b_no_offset[:, 3:7], self._offset_pos)\n",
    "            # Adjust the linear velocity to account for the offset\n",
    "            self._ee_vel_b[:, :3] += torch.cross(self._ee_vel_b[:, 3:], r_offset_b, dim=-1)\n",
    "            # Angular velocity is not affected by the offset\n",
    "\n",
    "    def _compute_ee_force(self):\n",
    "        \"\"\"Computes the contact forces on the ee frame in root frame.\"\"\"\n",
    "        # Obtain contact forces only if the contact sensor is available\n",
    "        if self._contact_sensor is not None:\n",
    "            self._contact_sensor.update(self._sim_dt)\n",
    "            self._ee_force_w[:] = self._contact_sensor.data.net_forces_w[:, 0, :]  # type: ignore\n",
    "            # Rotate forces and torques into root frame\n",
    "            self._ee_force_b[:] = math_utils.quat_apply_inverse(self._asset.data.root_quat_w, self._ee_force_w)\n",
    "\n",
    "    def _compute_joint_states(self):\n",
    "        \"\"\"Computes the joint states for operational space control.\"\"\"\n",
    "        # Extract joint positions and velocities\n",
    "        self._joint_pos[:] = self._asset.data.joint_pos[:, self._joint_ids]\n",
    "        self._joint_vel[:] = self._asset.data.joint_vel[:, self._joint_ids]\n",
    "\n",
    "    def _compute_task_frame_pose(self):\n",
    "        \"\"\"Computes the pose of the task frame in root frame.\"\"\"\n",
    "        # Update task frame pose if task frame rigidbody is provided\n",
    "        if self._task_frame_transformer is not None and self._task_frame_pose_b is not None:\n",
    "            self._task_frame_transformer.update(self._sim_dt)\n",
    "            # Calculate the pose of the task frame in the root frame\n",
    "            self._task_frame_pose_b[:, :3], self._task_frame_pose_b[:, 3:] = math_utils.subtract_frame_transforms(\n",
    "                self._asset.data.root_pos_w,\n",
    "                self._asset.data.root_quat_w,\n",
    "                self._task_frame_transformer.data.target_pos_w[:, 0, :],\n",
    "                self._task_frame_transformer.data.target_quat_w[:, 0, :],\n",
    "            )\n",
    "\n",
    "    def _preprocess_actions(self, actions: torch.Tensor):\n",
    "        \"\"\"Pre-processes the raw actions for operational space control.\n",
    "\n",
    "        Args:\n",
    "            actions (torch.Tensor): The raw actions for operational space control. It is a tensor of\n",
    "                shape (``num_envs``, ``action_dim``).\n",
    "        \"\"\"\n",
    "        # Store the raw actions. Please note that the actions contain task space targets\n",
    "        # (in the order of the target_types), and possibly the impedance parameters depending on impedance_mode.\n",
    "        self._raw_actions[:] = actions\n",
    "        # Initialize the processed actions with raw actions.\n",
    "        self._processed_actions[:] = self._raw_actions\n",
    "        # Go through the command types one by one, and apply the pre-processing if needed.\n",
    "        if self._pose_abs_idx is not None:\n",
    "            self._processed_actions[:, self._pose_abs_idx : self._pose_abs_idx + 3] *= self._position_scale\n",
    "            self._processed_actions[:, self._pose_abs_idx + 3 : self._pose_abs_idx + 7] *= self._orientation_scale\n",
    "        if self._pose_rel_idx is not None:\n",
    "            self._processed_actions[:, self._pose_rel_idx : self._pose_rel_idx + 3] *= self._position_scale\n",
    "            self._processed_actions[:, self._pose_rel_idx + 3 : self._pose_rel_idx + 6] *= self._orientation_scale\n",
    "        if self._wrench_abs_idx is not None:\n",
    "            self._processed_actions[:, self._wrench_abs_idx : self._wrench_abs_idx + 6] *= self._wrench_scale\n",
    "        if self._stiffness_idx is not None:\n",
    "            self._processed_actions[:, self._stiffness_idx : self._stiffness_idx + 6] *= self._stiffness_scale\n",
    "            self._processed_actions[:, self._stiffness_idx : self._stiffness_idx + 6] = torch.clamp(\n",
    "                self._processed_actions[:, self._stiffness_idx : self._stiffness_idx + 6],\n",
    "                min=self.cfg.controller_cfg.motion_stiffness_limits_task[0],\n",
    "                max=self.cfg.controller_cfg.motion_stiffness_limits_task[1],\n",
    "            )\n",
    "        if self._damping_ratio_idx is not None:\n",
    "            self._processed_actions[\n",
    "                :, self._damping_ratio_idx : self._damping_ratio_idx + 6\n",
    "            ] *= self._damping_ratio_scale\n",
    "            self._processed_actions[:, self._damping_ratio_idx : self._damping_ratio_idx + 6] = torch.clamp(\n",
    "                self._processed_actions[:, self._damping_ratio_idx : self._damping_ratio_idx + 6],\n",
    "                min=self.cfg.controller_cfg.motion_damping_ratio_limits_task[0],\n",
    "                max=self.cfg.controller_cfg.motion_damping_ratio_limits_task[1],\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
