{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62afbfa2",
   "metadata": {},
   "source": [
    "# Inherit Locomotion Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a47276",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from isaaclab_assets import HUMANOID_CFG\n",
    "\n",
    "import isaaclab.sim as sim_utils\n",
    "from isaaclab.assets import ArticulationCfg\n",
    "from isaaclab.envs import DirectRLEnvCfg\n",
    "from isaaclab.scene import InteractiveSceneCfg\n",
    "from isaaclab.sim import SimulationCfg\n",
    "from isaaclab.terrains import TerrainImporterCfg\n",
    "from isaaclab.utils import configclass\n",
    "\n",
    "# from isaaclab_tasks.direct.locomotion.locomotion_env import LocomotionEnv\n",
    "from isaaclab_tutorial.tasks.direct.locomotion.locomotion_env import LocomotionEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c3bbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_angle(x):\n",
    "    return torch.atan2(torch.sin(x), torch.cos(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d667446",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocomotionEnv(DirectRLEnv):\n",
    "    cfg: DirectRLEnvCfg\n",
    "\n",
    "    def __init__(self, cfg: DirectRLEnvCfg, render_mode: str | None = None, **kwargs):\n",
    "        super().__init__(cfg, render_mode, **kwargs)\n",
    "\n",
    "        self.action_scale = self.cfg.action_scale\n",
    "        self.joint_gears = torch.tensor(self.cfg.joint_gears, dtype=torch.float32, device=self.sim.device)\n",
    "        self.motor_effort_ratio = torch.ones_like(self.joint_gears, device=self.sim.device)\n",
    "        self._joint_dof_idx, _ = self.robot.find_joints(\".*\")\n",
    "\n",
    "        self.potentials = torch.zeros(self.num_envs, dtype=torch.float32, device=self.sim.device)\n",
    "        self.prev_potentials = torch.zeros_like(self.potentials)\n",
    "        self.targets = torch.tensor([1000, 0, 0], dtype=torch.float32, device=self.sim.device).repeat(\n",
    "            (self.num_envs, 1)\n",
    "        )\n",
    "        self.targets += self.scene.env_origins\n",
    "        self.start_rotation = torch.tensor([1, 0, 0, 0], device=self.sim.device, dtype=torch.float32)\n",
    "        self.up_vec = torch.tensor([0, 0, 1], dtype=torch.float32, device=self.sim.device).repeat((self.num_envs, 1))\n",
    "        self.heading_vec = torch.tensor([1, 0, 0], dtype=torch.float32, device=self.sim.device).repeat(\n",
    "            (self.num_envs, 1)\n",
    "        )\n",
    "        self.inv_start_rot = quat_conjugate(self.start_rotation).repeat((self.num_envs, 1))\n",
    "        self.basis_vec0 = self.heading_vec.clone()\n",
    "        self.basis_vec1 = self.up_vec.clone()\n",
    "\n",
    "    def _setup_scene(self):\n",
    "        self.robot = Articulation(self.cfg.robot)\n",
    "        # add ground plane\n",
    "        self.cfg.terrain.num_envs = self.scene.cfg.num_envs\n",
    "        self.cfg.terrain.env_spacing = self.scene.cfg.env_spacing\n",
    "        self.terrain = self.cfg.terrain.class_type(self.cfg.terrain)\n",
    "        # clone and replicate\n",
    "        self.scene.clone_environments(copy_from_source=False)\n",
    "        # we need to explicitly filter collisions for CPU simulation\n",
    "        if self.device == \"cpu\":\n",
    "            self.scene.filter_collisions(global_prim_paths=[self.cfg.terrain.prim_path])\n",
    "        # add articulation to scene\n",
    "        self.scene.articulations[\"robot\"] = self.robot\n",
    "        # add lights\n",
    "        light_cfg = sim_utils.DomeLightCfg(intensity=2000.0, color=(0.75, 0.75, 0.75))\n",
    "        light_cfg.func(\"/World/Light\", light_cfg)\n",
    "\n",
    "    def _pre_physics_step(self, actions: torch.Tensor):\n",
    "        self.actions = actions.clone()\n",
    "\n",
    "    def _apply_action(self):\n",
    "        forces = self.action_scale * self.joint_gears * self.actions\n",
    "        self.robot.set_joint_effort_target(forces, joint_ids=self._joint_dof_idx)\n",
    "\n",
    "    def _compute_intermediate_values(self):\n",
    "        self.torso_position, self.torso_rotation = self.robot.data.root_pos_w, self.robot.data.root_quat_w\n",
    "        self.velocity, self.ang_velocity = self.robot.data.root_lin_vel_w, self.robot.data.root_ang_vel_w\n",
    "        self.dof_pos, self.dof_vel = self.robot.data.joint_pos, self.robot.data.joint_vel\n",
    "\n",
    "        (\n",
    "            self.up_proj,\n",
    "            self.heading_proj,\n",
    "            self.up_vec,\n",
    "            self.heading_vec,\n",
    "            self.vel_loc,\n",
    "            self.angvel_loc,\n",
    "            self.roll,\n",
    "            self.pitch,\n",
    "            self.yaw,\n",
    "            self.angle_to_target,\n",
    "            self.dof_pos_scaled,\n",
    "            self.prev_potentials,\n",
    "            self.potentials,\n",
    "        ) = compute_intermediate_values(\n",
    "            self.targets,\n",
    "            self.torso_position,\n",
    "            self.torso_rotation,\n",
    "            self.velocity,\n",
    "            self.ang_velocity,\n",
    "            self.dof_pos,\n",
    "            self.robot.data.soft_joint_pos_limits[0, :, 0],\n",
    "            self.robot.data.soft_joint_pos_limits[0, :, 1],\n",
    "            self.inv_start_rot,\n",
    "            self.basis_vec0,\n",
    "            self.basis_vec1,\n",
    "            self.potentials,\n",
    "            self.prev_potentials,\n",
    "            self.cfg.sim.dt,\n",
    "        )\n",
    "\n",
    "    def _get_observations(self) -> dict:\n",
    "        obs = torch.cat(\n",
    "            (\n",
    "                self.torso_position[:, 2].view(-1, 1),\n",
    "                self.vel_loc,\n",
    "                self.angvel_loc * self.cfg.angular_velocity_scale,\n",
    "                normalize_angle(self.yaw).unsqueeze(-1),\n",
    "                normalize_angle(self.roll).unsqueeze(-1),\n",
    "                normalize_angle(self.angle_to_target).unsqueeze(-1),\n",
    "                self.up_proj.unsqueeze(-1),\n",
    "                self.heading_proj.unsqueeze(-1),\n",
    "                self.dof_pos_scaled,\n",
    "                self.dof_vel * self.cfg.dof_vel_scale,\n",
    "                self.actions,\n",
    "            ),\n",
    "            dim=-1,\n",
    "        )\n",
    "        observations = {\"policy\": obs}\n",
    "        return observations\n",
    "\n",
    "    def _get_rewards(self) -> torch.Tensor:\n",
    "        total_reward = compute_rewards(\n",
    "            self.actions,\n",
    "            self.reset_terminated,\n",
    "            self.cfg.up_weight,\n",
    "            self.cfg.heading_weight,\n",
    "            self.heading_proj,\n",
    "            self.up_proj,\n",
    "            self.dof_vel,\n",
    "            self.dof_pos_scaled,\n",
    "            self.potentials,\n",
    "            self.prev_potentials,\n",
    "            self.cfg.actions_cost_scale,\n",
    "            self.cfg.energy_cost_scale,\n",
    "            self.cfg.dof_vel_scale,\n",
    "            self.cfg.death_cost,\n",
    "            self.cfg.alive_reward_scale,\n",
    "            self.motor_effort_ratio,\n",
    "        )\n",
    "        return total_reward\n",
    "\n",
    "    def _get_dones(self) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        self._compute_intermediate_values()\n",
    "        time_out = self.episode_length_buf >= self.max_episode_length - 1\n",
    "        died = self.torso_position[:, 2] < self.cfg.termination_height\n",
    "        return died, time_out\n",
    "\n",
    "    def _reset_idx(self, env_ids: torch.Tensor | None):\n",
    "        if env_ids is None or len(env_ids) == self.num_envs:\n",
    "            env_ids = self.robot._ALL_INDICES\n",
    "        self.robot.reset(env_ids)\n",
    "        super()._reset_idx(env_ids)\n",
    "\n",
    "        joint_pos = self.robot.data.default_joint_pos[env_ids]\n",
    "        joint_vel = self.robot.data.default_joint_vel[env_ids]\n",
    "        default_root_state = self.robot.data.default_root_state[env_ids]\n",
    "        default_root_state[:, :3] += self.scene.env_origins[env_ids]\n",
    "\n",
    "        self.robot.write_root_pose_to_sim(default_root_state[:, :7], env_ids)\n",
    "        self.robot.write_root_velocity_to_sim(default_root_state[:, 7:], env_ids)\n",
    "        self.robot.write_joint_state_to_sim(joint_pos, joint_vel, None, env_ids)\n",
    "\n",
    "        to_target = self.targets[env_ids] - default_root_state[:, :3]\n",
    "        to_target[:, 2] = 0.0\n",
    "        self.potentials[env_ids] = -torch.norm(to_target, p=2, dim=-1) / self.cfg.sim.dt\n",
    "\n",
    "        self._compute_intermediate_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ed4551",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.jit.script\n",
    "def compute_rewards(\n",
    "    actions: torch.Tensor,\n",
    "    reset_terminated: torch.Tensor,\n",
    "    up_weight: float,\n",
    "    heading_weight: float,\n",
    "    heading_proj: torch.Tensor,\n",
    "    up_proj: torch.Tensor,\n",
    "    dof_vel: torch.Tensor,\n",
    "    dof_pos_scaled: torch.Tensor,\n",
    "    potentials: torch.Tensor,\n",
    "    prev_potentials: torch.Tensor,\n",
    "    actions_cost_scale: float,\n",
    "    energy_cost_scale: float,\n",
    "    dof_vel_scale: float,\n",
    "    death_cost: float,\n",
    "    alive_reward_scale: float,\n",
    "    motor_effort_ratio: torch.Tensor,\n",
    "):\n",
    "    heading_weight_tensor = torch.ones_like(heading_proj) * heading_weight\n",
    "    heading_reward = torch.where(heading_proj > 0.8, heading_weight_tensor, heading_weight * heading_proj / 0.8)\n",
    "\n",
    "    # aligning up axis of robot and environment\n",
    "    up_reward = torch.zeros_like(heading_reward)\n",
    "    up_reward = torch.where(up_proj > 0.93, up_reward + up_weight, up_reward)\n",
    "\n",
    "    # energy penalty for movement\n",
    "    actions_cost = torch.sum(actions**2, dim=-1)\n",
    "    electricity_cost = torch.sum(\n",
    "        torch.abs(actions * dof_vel * dof_vel_scale) * motor_effort_ratio.unsqueeze(0),\n",
    "        dim=-1,\n",
    "    )\n",
    "\n",
    "    # dof at limit cost\n",
    "    dof_at_limit_cost = torch.sum(dof_pos_scaled > 0.98, dim=-1)\n",
    "\n",
    "    # reward for duration of staying alive\n",
    "    alive_reward = torch.ones_like(potentials) * alive_reward_scale\n",
    "    progress_reward = potentials - prev_potentials\n",
    "\n",
    "    total_reward = (\n",
    "        progress_reward\n",
    "        + alive_reward\n",
    "        + up_reward\n",
    "        + heading_reward\n",
    "        - actions_cost_scale * actions_cost\n",
    "        - energy_cost_scale * electricity_cost\n",
    "        - dof_at_limit_cost\n",
    "    )\n",
    "    # adjust reward for fallen agents\n",
    "    total_reward = torch.where(reset_terminated, torch.ones_like(total_reward) * death_cost, total_reward)\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415ea9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.jit.script\n",
    "def compute_intermediate_values(\n",
    "    targets: torch.Tensor,\n",
    "    torso_position: torch.Tensor,\n",
    "    torso_rotation: torch.Tensor,\n",
    "    velocity: torch.Tensor,\n",
    "    ang_velocity: torch.Tensor,\n",
    "    dof_pos: torch.Tensor,\n",
    "    dof_lower_limits: torch.Tensor,\n",
    "    dof_upper_limits: torch.Tensor,\n",
    "    inv_start_rot: torch.Tensor,\n",
    "    basis_vec0: torch.Tensor,\n",
    "    basis_vec1: torch.Tensor,\n",
    "    potentials: torch.Tensor,\n",
    "    prev_potentials: torch.Tensor,\n",
    "    dt: float,\n",
    "):\n",
    "    to_target = targets - torso_position\n",
    "    to_target[:, 2] = 0.0\n",
    "\n",
    "    torso_quat, up_proj, heading_proj, up_vec, heading_vec = compute_heading_and_up(\n",
    "        torso_rotation, inv_start_rot, to_target, basis_vec0, basis_vec1, 2\n",
    "    )\n",
    "\n",
    "    vel_loc, angvel_loc, roll, pitch, yaw, angle_to_target = compute_rot(\n",
    "        torso_quat, velocity, ang_velocity, targets, torso_position\n",
    "    )\n",
    "\n",
    "    dof_pos_scaled = torch_utils.maths.unscale(dof_pos, dof_lower_limits, dof_upper_limits)\n",
    "\n",
    "    to_target = targets - torso_position\n",
    "    to_target[:, 2] = 0.0\n",
    "    prev_potentials[:] = potentials\n",
    "    potentials = -torch.norm(to_target, p=2, dim=-1) / dt\n",
    "\n",
    "    return (\n",
    "        up_proj,\n",
    "        heading_proj,\n",
    "        up_vec,\n",
    "        heading_vec,\n",
    "        vel_loc,\n",
    "        angvel_loc,\n",
    "        roll,\n",
    "        pitch,\n",
    "        yaw,\n",
    "        angle_to_target,\n",
    "        dof_pos_scaled,\n",
    "        prev_potentials,\n",
    "        potentials,\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
