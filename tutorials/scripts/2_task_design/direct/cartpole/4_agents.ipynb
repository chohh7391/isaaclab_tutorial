{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c56aeec",
   "metadata": {},
   "source": [
    "# RL Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257bf285",
   "metadata": {
    "vscode": {
     "languageId": "yaml"
    }
   },
   "outputs": [],
   "source": [
    "# Copyright (c) 2022-2025, The Isaac Lab Project Developers (https://github.com/isaac-sim/IsaacLab/blob/main/CONTRIBUTORS.md).\n",
    "# All rights reserved.\n",
    "#\n",
    "# SPDX-License-Identifier: BSD-3-Clause\n",
    "\n",
    "params:\n",
    "  seed: 42\n",
    "\n",
    "  # environment wrapper clipping\n",
    "  env:\n",
    "    # added to the wrapper\n",
    "    clip_observations: 5.0\n",
    "    # can make custom wrapper?\n",
    "    clip_actions: 1.0\n",
    "\n",
    "  algo:\n",
    "    name: a2c_continuous\n",
    "\n",
    "  model:\n",
    "    name: continuous_a2c_logstd\n",
    "\n",
    "  # doesn't have this fine grained control but made it close\n",
    "  network:\n",
    "    name: actor_critic\n",
    "    separate: False\n",
    "    space:\n",
    "      continuous:\n",
    "        mu_activation: None\n",
    "        sigma_activation: None\n",
    "\n",
    "        mu_init:\n",
    "          name: default\n",
    "        sigma_init:\n",
    "          name: const_initializer\n",
    "          val: 0\n",
    "        fixed_sigma: True\n",
    "    mlp:\n",
    "      units: [32, 32]\n",
    "      activation: elu\n",
    "      d2rl: False\n",
    "\n",
    "      initializer:\n",
    "        name: default\n",
    "      regularizer:\n",
    "        name: None\n",
    "\n",
    "  load_checkpoint: False # flag which sets whether to load the checkpoint\n",
    "  load_path: '' # path to the checkpoint to load\n",
    "\n",
    "  config:\n",
    "    name: cartpole_direct\n",
    "    env_name: rlgpu\n",
    "    device: 'cuda:0'\n",
    "    device_name: 'cuda:0'\n",
    "    multi_gpu: False\n",
    "    ppo: True\n",
    "    mixed_precision: False\n",
    "    normalize_input: True\n",
    "    normalize_value: True\n",
    "    num_actors: -1  # configured from the script (based on num_envs)\n",
    "    reward_shaper:\n",
    "      scale_value: 0.1\n",
    "    normalize_advantage: True\n",
    "    gamma: 0.99\n",
    "    tau : 0.95\n",
    "    learning_rate: 5e-4\n",
    "    lr_schedule: adaptive\n",
    "    kl_threshold: 0.008\n",
    "    score_to_win: 20000\n",
    "    max_epochs: 150\n",
    "    save_best_after: 50\n",
    "    save_frequency: 25\n",
    "    grad_norm: 1.0\n",
    "    entropy_coef: 0.0\n",
    "    truncate_grads: True\n",
    "    e_clip: 0.2\n",
    "    horizon_length: 32\n",
    "    minibatch_size: 16384\n",
    "    mini_epochs: 8\n",
    "    critic_coef: 4\n",
    "    clip_value: True\n",
    "    seq_length: 4\n",
    "    bounds_loss_coef: 0.0001\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3a78bf",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c1db1a",
   "metadata": {
    "vscode": {
     "languageId": "yaml"
    }
   },
   "outputs": [],
   "source": [
    "# Copyright (c) 2022-2025, The Isaac Lab Project Developers (https://github.com/isaac-sim/IsaacLab/blob/main/CONTRIBUTORS.md).\n",
    "# All rights reserved.\n",
    "#\n",
    "# SPDX-License-Identifier: BSD-3-Clause\n",
    "\n",
    "params:\n",
    "  seed: 42\n",
    "\n",
    "  # environment wrapper clipping\n",
    "  env:\n",
    "    # added to the wrapper\n",
    "    clip_observations: 5.0\n",
    "    # can make custom wrapper?\n",
    "    clip_actions: 1.0\n",
    "\n",
    "  algo:\n",
    "    name: a2c_continuous\n",
    "\n",
    "  model:\n",
    "    name: continuous_a2c_logstd\n",
    "\n",
    "  # doesn't have this fine grained control but made it close\n",
    "  network:\n",
    "    name: actor_critic\n",
    "    separate: False\n",
    "    space:\n",
    "      continuous:\n",
    "        mu_activation: None\n",
    "        sigma_activation: None\n",
    "\n",
    "        mu_init:\n",
    "          name: default\n",
    "        sigma_init:\n",
    "          name: const_initializer\n",
    "          val: 0\n",
    "        fixed_sigma: True\n",
    "    cnn:\n",
    "      type: conv2d\n",
    "      activation: relu\n",
    "      initializer:\n",
    "          name: default\n",
    "      regularizer:\n",
    "        name: None\n",
    "      convs:\n",
    "        - filters: 32\n",
    "          kernel_size: 8\n",
    "          strides: 4\n",
    "          padding: 0\n",
    "        - filters: 64\n",
    "          kernel_size: 4\n",
    "          strides: 2\n",
    "          padding: 0\n",
    "        - filters: 64\n",
    "          kernel_size: 3\n",
    "          strides: 1\n",
    "          padding: 0\n",
    "\n",
    "    mlp:\n",
    "      units: [512]\n",
    "      activation: elu\n",
    "      initializer:\n",
    "          name: default\n",
    "\n",
    "  load_checkpoint: False # flag which sets whether to load the checkpoint\n",
    "  load_path: '' # path to the checkpoint to load\n",
    "\n",
    "  config:\n",
    "    name: cartpole_camera_direct\n",
    "    env_name: rlgpu\n",
    "    device: 'cuda:0'\n",
    "    device_name: 'cuda:0'\n",
    "    multi_gpu: False\n",
    "    ppo: True\n",
    "    mixed_precision: False\n",
    "    normalize_input: False\n",
    "    normalize_value: True\n",
    "    num_actors: -1  # configured from the script (based on num_envs)\n",
    "    reward_shaper:\n",
    "      scale_value: 1.0\n",
    "    normalize_advantage: True\n",
    "    gamma: 0.99\n",
    "    tau : 0.95\n",
    "    learning_rate: 1e-4\n",
    "    lr_schedule: adaptive\n",
    "    kl_threshold: 0.008\n",
    "    score_to_win: 20000\n",
    "    max_epochs: 500\n",
    "    save_best_after: 50\n",
    "    save_frequency: 25\n",
    "    grad_norm: 1.0\n",
    "    entropy_coef: 0.0\n",
    "    truncate_grads: True\n",
    "    e_clip: 0.2\n",
    "    horizon_length: 64\n",
    "    minibatch_size: 2048\n",
    "    mini_epochs: 4\n",
    "    critic_coef: 2\n",
    "    clip_value: True\n",
    "    seq_length: 4\n",
    "    bounds_loss_coef: 0.0001\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b52c90",
   "metadata": {},
   "source": [
    "# RSL RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a9f6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2022-2025, The Isaac Lab Project Developers (https://github.com/isaac-sim/IsaacLab/blob/main/CONTRIBUTORS.md).\n",
    "# All rights reserved.\n",
    "#\n",
    "# SPDX-License-Identifier: BSD-3-Clause\n",
    "\n",
    "from isaaclab.utils import configclass\n",
    "\n",
    "from isaaclab_rl.rsl_rl import RslRlOnPolicyRunnerCfg, RslRlPpoActorCriticCfg, RslRlPpoAlgorithmCfg\n",
    "\n",
    "\n",
    "@configclass\n",
    "class CartpolePPORunnerCfg(RslRlOnPolicyRunnerCfg):\n",
    "    num_steps_per_env = 16\n",
    "    max_iterations = 150\n",
    "    save_interval = 50\n",
    "    experiment_name = \"cartpole_direct\"\n",
    "    policy = RslRlPpoActorCriticCfg(\n",
    "        init_noise_std=1.0,\n",
    "        actor_obs_normalization=False,\n",
    "        critic_obs_normalization=False,\n",
    "        actor_hidden_dims=[32, 32],\n",
    "        critic_hidden_dims=[32, 32],\n",
    "        activation=\"elu\",\n",
    "    )\n",
    "    algorithm = RslRlPpoAlgorithmCfg(\n",
    "        value_loss_coef=1.0,\n",
    "        use_clipped_value_loss=True,\n",
    "        clip_param=0.2,\n",
    "        entropy_coef=0.005,\n",
    "        num_learning_epochs=5,\n",
    "        num_mini_batches=4,\n",
    "        learning_rate=1.0e-3,\n",
    "        schedule=\"adaptive\",\n",
    "        gamma=0.99,\n",
    "        lam=0.95,\n",
    "        desired_kl=0.01,\n",
    "        max_grad_norm=1.0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d2e4fe",
   "metadata": {},
   "source": [
    "# SKRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8ba303",
   "metadata": {
    "vscode": {
     "languageId": "yaml"
    }
   },
   "outputs": [],
   "source": [
    "# Copyright (c) 2022-2025, The Isaac Lab Project Developers (https://github.com/isaac-sim/IsaacLab/blob/main/CONTRIBUTORS.md).\n",
    "# All rights reserved.\n",
    "#\n",
    "# SPDX-License-Identifier: BSD-3-Clause\n",
    "\n",
    "seed: 42\n",
    "\n",
    "\n",
    "# Models are instantiated using skrl's model instantiator utility\n",
    "# https://skrl.readthedocs.io/en/latest/api/utils/model_instantiators.html\n",
    "models:\n",
    "  separate: False\n",
    "  policy:  # see gaussian_model parameters\n",
    "    class: GaussianMixin\n",
    "    clip_actions: False\n",
    "    clip_log_std: True\n",
    "    min_log_std: -20.0\n",
    "    max_log_std: 2.0\n",
    "    initial_log_std: 0.0\n",
    "    network:\n",
    "      - name: net\n",
    "        input: STATES\n",
    "        layers: [32, 32]\n",
    "        activations: elu\n",
    "    output: ACTIONS\n",
    "  value:  # see deterministic_model parameters\n",
    "    class: DeterministicMixin\n",
    "    clip_actions: False\n",
    "    network:\n",
    "      - name: net\n",
    "        input: STATES\n",
    "        layers: [32, 32]\n",
    "        activations: elu\n",
    "    output: ONE\n",
    "\n",
    "\n",
    "# Rollout memory\n",
    "# https://skrl.readthedocs.io/en/latest/api/memories/random.html\n",
    "memory:\n",
    "  class: RandomMemory\n",
    "  memory_size: -1  # automatically determined (same as agent:rollouts)\n",
    "\n",
    "\n",
    "# PPO agent configuration (field names are from PPO_DEFAULT_CONFIG)\n",
    "# https://skrl.readthedocs.io/en/latest/api/agents/ppo.html\n",
    "agent:\n",
    "  class: PPO\n",
    "  rollouts: 32\n",
    "  learning_epochs: 8\n",
    "  mini_batches: 8\n",
    "  discount_factor: 0.99\n",
    "  lambda: 0.95\n",
    "  learning_rate: 5.0e-04\n",
    "  learning_rate_scheduler: KLAdaptiveLR\n",
    "  learning_rate_scheduler_kwargs:\n",
    "    kl_threshold: 0.008\n",
    "  state_preprocessor: RunningStandardScaler\n",
    "  state_preprocessor_kwargs: null\n",
    "  value_preprocessor: RunningStandardScaler\n",
    "  value_preprocessor_kwargs: null\n",
    "  random_timesteps: 0\n",
    "  learning_starts: 0\n",
    "  grad_norm_clip: 1.0\n",
    "  ratio_clip: 0.2\n",
    "  value_clip: 0.2\n",
    "  clip_predicted_values: True\n",
    "  entropy_loss_scale: 0.0\n",
    "  value_loss_scale: 2.0\n",
    "  kl_threshold: 0.0\n",
    "  rewards_shaper_scale: 0.1\n",
    "  time_limit_bootstrap: False\n",
    "  # logging and checkpoint\n",
    "  experiment:\n",
    "    directory: \"cartpole_direct\"\n",
    "    experiment_name: \"\"\n",
    "    write_interval: auto\n",
    "    checkpoint_interval: auto\n",
    "\n",
    "\n",
    "# Sequential trainer\n",
    "# https://skrl.readthedocs.io/en/latest/api/trainers/sequential.html\n",
    "trainer:\n",
    "  class: SequentialTrainer\n",
    "  timesteps: 4800\n",
    "  environment_info: log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78094066",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6629f4",
   "metadata": {
    "vscode": {
     "languageId": "yaml"
    }
   },
   "outputs": [],
   "source": [
    "# Copyright (c) 2022-2025, The Isaac Lab Project Developers (https://github.com/isaac-sim/IsaacLab/blob/main/CONTRIBUTORS.md).\n",
    "# All rights reserved.\n",
    "#\n",
    "# SPDX-License-Identifier: BSD-3-Clause\n",
    "\n",
    "seed: 42\n",
    "\n",
    "\n",
    "# Models are instantiated using skrl's model instantiator utility\n",
    "# https://skrl.readthedocs.io/en/latest/api/utils/model_instantiators.html\n",
    "models:\n",
    "  separate: False\n",
    "  policy:  # see gaussian_model parameters\n",
    "    class: GaussianMixin\n",
    "    clip_actions: False\n",
    "    clip_log_std: True\n",
    "    min_log_std: -20.0\n",
    "    max_log_std: 2.0\n",
    "    initial_log_std: 0.0\n",
    "    network:\n",
    "      - name: features_extractor\n",
    "        input: permute(STATES, (0, 3, 1, 2))  # PyTorch NHWC -> NCHW. Warning: don't permute for JAX since it expects NHWC\n",
    "        layers:\n",
    "          - conv2d: {out_channels: 32, kernel_size: 8, stride: 4, padding: 0}\n",
    "          - conv2d: {out_channels: 64, kernel_size: 4, stride: 2, padding: 0}\n",
    "          - conv2d: {out_channels: 64, kernel_size: 3, stride: 1, padding: 0}\n",
    "          - flatten\n",
    "        activations: relu\n",
    "      - name: net\n",
    "        input: features_extractor\n",
    "        layers: [512]\n",
    "        activations: elu\n",
    "    output: ACTIONS\n",
    "  value:  # see deterministic_model parameters\n",
    "    class: DeterministicMixin\n",
    "    clip_actions: False\n",
    "    network:\n",
    "      - name: features_extractor\n",
    "        input: permute(STATES, (0, 3, 1, 2))  # PyTorch NHWC -> NCHW. Warning: don't permute for JAX since it expects NHWC\n",
    "        layers:\n",
    "          - conv2d: {out_channels: 32, kernel_size: 8, stride: 4, padding: 0}\n",
    "          - conv2d: {out_channels: 64, kernel_size: 4, stride: 2, padding: 0}\n",
    "          - conv2d: {out_channels: 64, kernel_size: 3, stride: 1, padding: 0}\n",
    "          - flatten\n",
    "        activations: relu\n",
    "      - name: net\n",
    "        input: features_extractor\n",
    "        layers: [512]\n",
    "        activations: elu\n",
    "    output: ONE\n",
    "\n",
    "\n",
    "# Rollout memory\n",
    "# https://skrl.readthedocs.io/en/latest/api/memories/random.html\n",
    "memory:\n",
    "  class: RandomMemory\n",
    "  memory_size: -1  # automatically determined (same as agent:rollouts)\n",
    "\n",
    "\n",
    "# PPO agent configuration (field names are from PPO_DEFAULT_CONFIG)\n",
    "# https://skrl.readthedocs.io/en/latest/api/agents/ppo.html\n",
    "agent:\n",
    "  class: PPO\n",
    "  rollouts: 64\n",
    "  learning_epochs: 4\n",
    "  mini_batches: 32\n",
    "  discount_factor: 0.99\n",
    "  lambda: 0.95\n",
    "  learning_rate: 1.0e-04\n",
    "  learning_rate_scheduler: KLAdaptiveLR\n",
    "  learning_rate_scheduler_kwargs:\n",
    "    kl_threshold: 0.008\n",
    "  state_preprocessor: null\n",
    "  state_preprocessor_kwargs: null\n",
    "  value_preprocessor: RunningStandardScaler\n",
    "  value_preprocessor_kwargs: null\n",
    "  random_timesteps: 0\n",
    "  learning_starts: 0\n",
    "  grad_norm_clip: 1.0\n",
    "  ratio_clip: 0.2\n",
    "  value_clip: 0.2\n",
    "  clip_predicted_values: True\n",
    "  entropy_loss_scale: 0.0\n",
    "  value_loss_scale: 1.0\n",
    "  kl_threshold: 0.0\n",
    "  rewards_shaper_scale: 1.0\n",
    "  time_limit_bootstrap: False\n",
    "  # logging and checkpoint\n",
    "  experiment:\n",
    "    directory: \"cartpole_camera_direct\"\n",
    "    experiment_name: \"\"\n",
    "    write_interval: auto\n",
    "    checkpoint_interval: auto\n",
    "\n",
    "\n",
    "# Sequential trainer\n",
    "# https://skrl.readthedocs.io/en/latest/api/trainers/sequential.html\n",
    "trainer:\n",
    "  class: SequentialTrainer\n",
    "  timesteps: 32000\n",
    "  environment_info: log\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
